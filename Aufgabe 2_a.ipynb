{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your main Jupyter notebook file and train all three autoencoder using\n",
    "the 40 training signals with the parameters given in Table 1.\n",
    "Hint : Test different learning rates first, but use the same learning rate for all\n",
    "three models at the end. Use the shuffle mode for the data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 0.03363988921046257\n",
      "Epoch 0, Batch 1, Loss: 0.032993778586387634\n",
      "Epoch 0, Average Loss: 0.0333168338984251\n",
      "Epoch 1, Batch 0, Loss: 0.03238619863986969\n",
      "Epoch 1, Batch 1, Loss: 0.03243592754006386\n",
      "Epoch 1, Average Loss: 0.032411063089966774\n",
      "Epoch 2, Batch 0, Loss: 0.031663138419389725\n",
      "Epoch 2, Batch 1, Loss: 0.03051569126546383\n",
      "Epoch 2, Average Loss: 0.031089414842426777\n",
      "Epoch 3, Batch 0, Loss: 0.03043435886502266\n",
      "Epoch 3, Batch 1, Loss: 0.03110460750758648\n",
      "Epoch 3, Average Loss: 0.03076948318630457\n",
      "Epoch 4, Batch 0, Loss: 0.029657600447535515\n",
      "Epoch 4, Batch 1, Loss: 0.03032148815691471\n",
      "Epoch 4, Average Loss: 0.029989544302225113\n",
      "Epoch 5, Batch 0, Loss: 0.029263639822602272\n",
      "Epoch 5, Batch 1, Loss: 0.0282729621976614\n",
      "Epoch 5, Average Loss: 0.028768301010131836\n",
      "Epoch 6, Batch 0, Loss: 0.028167439624667168\n",
      "Epoch 6, Batch 1, Loss: 0.029198693111538887\n",
      "Epoch 6, Average Loss: 0.028683066368103027\n",
      "Epoch 7, Batch 0, Loss: 0.027789399027824402\n",
      "Epoch 7, Batch 1, Loss: 0.027349989861249924\n",
      "Epoch 7, Average Loss: 0.027569694444537163\n",
      "Epoch 8, Batch 0, Loss: 0.02699984610080719\n",
      "Epoch 8, Batch 1, Loss: 0.02718243934214115\n",
      "Epoch 8, Average Loss: 0.02709114272147417\n",
      "Epoch 9, Batch 0, Loss: 0.025941742584109306\n",
      "Epoch 9, Batch 1, Loss: 0.028099901974201202\n",
      "Epoch 9, Average Loss: 0.027020822279155254\n",
      "Epoch 10, Batch 0, Loss: 0.025243816897273064\n",
      "Epoch 10, Batch 1, Loss: 0.02757168747484684\n",
      "Epoch 10, Average Loss: 0.026407752186059952\n",
      "Epoch 11, Batch 0, Loss: 0.02474959008395672\n",
      "Epoch 11, Batch 1, Loss: 0.026232479140162468\n",
      "Epoch 11, Average Loss: 0.025491034612059593\n",
      "Epoch 12, Batch 0, Loss: 0.024410780519247055\n",
      "Epoch 12, Batch 1, Loss: 0.024270541965961456\n",
      "Epoch 12, Average Loss: 0.024340661242604256\n",
      "Epoch 13, Batch 0, Loss: 0.024153925478458405\n",
      "Epoch 13, Batch 1, Loss: 0.022002579644322395\n",
      "Epoch 13, Average Loss: 0.0230782525613904\n",
      "Epoch 14, Batch 0, Loss: 0.02253800630569458\n",
      "Epoch 14, Batch 1, Loss: 0.0251940805464983\n",
      "Epoch 14, Average Loss: 0.02386604342609644\n",
      "Epoch 15, Batch 0, Loss: 0.022452402859926224\n",
      "Epoch 15, Batch 1, Loss: 0.022307727485895157\n",
      "Epoch 15, Average Loss: 0.02238006517291069\n",
      "Epoch 16, Batch 0, Loss: 0.021962467581033707\n",
      "Epoch 16, Batch 1, Loss: 0.021070603281259537\n",
      "Epoch 16, Average Loss: 0.02151653543114662\n",
      "Epoch 17, Batch 0, Loss: 0.021868659183382988\n",
      "Epoch 17, Batch 1, Loss: 0.018301036208868027\n",
      "Epoch 17, Average Loss: 0.020084847696125507\n",
      "Epoch 18, Batch 0, Loss: 0.020465834066271782\n",
      "Epoch 18, Batch 1, Loss: 0.020824268460273743\n",
      "Epoch 18, Average Loss: 0.020645051263272762\n",
      "Epoch 19, Batch 0, Loss: 0.020493295043706894\n",
      "Epoch 19, Batch 1, Loss: 0.01769072934985161\n",
      "Epoch 19, Average Loss: 0.01909201219677925\n",
      "Epoch 0, Batch 0, Loss: 0.017642229795455933\n",
      "Epoch 0, Batch 1, Loss: 0.016375502571463585\n",
      "Epoch 0, Average Loss: 0.01700886618345976\n",
      "Epoch 1, Batch 0, Loss: 0.01499448623508215\n",
      "Epoch 1, Batch 1, Loss: 0.013931052759289742\n",
      "Epoch 1, Average Loss: 0.014462769497185946\n",
      "Epoch 2, Batch 0, Loss: 0.013309352099895477\n",
      "Epoch 2, Batch 1, Loss: 0.014316855929791927\n",
      "Epoch 2, Average Loss: 0.013813104014843702\n",
      "Epoch 3, Batch 0, Loss: 0.01251764502376318\n",
      "Epoch 3, Batch 1, Loss: 0.01419568806886673\n",
      "Epoch 3, Average Loss: 0.013356666546314955\n",
      "Epoch 4, Batch 0, Loss: 0.012607833370566368\n",
      "Epoch 4, Batch 1, Loss: 0.012042702175676823\n",
      "Epoch 4, Average Loss: 0.012325267773121595\n",
      "Epoch 5, Batch 0, Loss: 0.01201178040355444\n",
      "Epoch 5, Batch 1, Loss: 0.013311044313013554\n",
      "Epoch 5, Average Loss: 0.012661412358283997\n",
      "Epoch 6, Batch 0, Loss: 0.012148096226155758\n",
      "Epoch 6, Batch 1, Loss: 0.011927003972232342\n",
      "Epoch 6, Average Loss: 0.01203755009919405\n",
      "Epoch 7, Batch 0, Loss: 0.012586875818669796\n",
      "Epoch 7, Batch 1, Loss: 0.009440083988010883\n",
      "Epoch 7, Average Loss: 0.01101347990334034\n",
      "Epoch 8, Batch 0, Loss: 0.011838790960609913\n",
      "Epoch 8, Batch 1, Loss: 0.011735414154827595\n",
      "Epoch 8, Average Loss: 0.011787102557718754\n",
      "Epoch 9, Batch 0, Loss: 0.011513298377394676\n",
      "Epoch 9, Batch 1, Loss: 0.012347722426056862\n",
      "Epoch 9, Average Loss: 0.011930510401725769\n",
      "Epoch 10, Batch 0, Loss: 0.011091908439993858\n",
      "Epoch 10, Batch 1, Loss: 0.013338007032871246\n",
      "Epoch 10, Average Loss: 0.012214957736432552\n",
      "Epoch 11, Batch 0, Loss: 0.011780811473727226\n",
      "Epoch 11, Batch 1, Loss: 0.009873771108686924\n",
      "Epoch 11, Average Loss: 0.010827291291207075\n",
      "Epoch 12, Batch 0, Loss: 0.011443814262747765\n",
      "Epoch 12, Batch 1, Loss: 0.010427110828459263\n",
      "Epoch 12, Average Loss: 0.010935462545603514\n",
      "Epoch 13, Batch 0, Loss: 0.011469747871160507\n",
      "Epoch 13, Batch 1, Loss: 0.009550990536808968\n",
      "Epoch 13, Average Loss: 0.010510369203984737\n",
      "Epoch 14, Batch 0, Loss: 0.010808796621859074\n",
      "Epoch 14, Batch 1, Loss: 0.011396328918635845\n",
      "Epoch 14, Average Loss: 0.01110256277024746\n",
      "Epoch 15, Batch 0, Loss: 0.011293774470686913\n",
      "Epoch 15, Batch 1, Loss: 0.008677174337208271\n",
      "Epoch 15, Average Loss: 0.009985474403947592\n",
      "Epoch 16, Batch 0, Loss: 0.010972533375024796\n",
      "Epoch 16, Batch 1, Loss: 0.009178475476801395\n",
      "Epoch 16, Average Loss: 0.010075504425913095\n",
      "Epoch 17, Batch 0, Loss: 0.010590032674372196\n",
      "Epoch 17, Batch 1, Loss: 0.009934566915035248\n",
      "Epoch 17, Average Loss: 0.010262299794703722\n",
      "Epoch 18, Batch 0, Loss: 0.010695363394916058\n",
      "Epoch 18, Batch 1, Loss: 0.008791431784629822\n",
      "Epoch 18, Average Loss: 0.00974339758977294\n",
      "Epoch 19, Batch 0, Loss: 0.010149144567549229\n",
      "Epoch 19, Batch 1, Loss: 0.01024128869175911\n",
      "Epoch 19, Average Loss: 0.010195216629654169\n",
      "Epoch 0, Batch 0, Loss: 0.01346453744918108\n",
      "Epoch 0, Batch 1, Loss: 0.013891544193029404\n",
      "Epoch 0, Average Loss: 0.013678040821105242\n",
      "Epoch 1, Batch 0, Loss: 0.012500914745032787\n",
      "Epoch 1, Batch 1, Loss: 0.011181915178894997\n",
      "Epoch 1, Average Loss: 0.011841414961963892\n",
      "Epoch 2, Batch 0, Loss: 0.011495244689285755\n",
      "Epoch 2, Batch 1, Loss: 0.01302117109298706\n",
      "Epoch 2, Average Loss: 0.012258207891136408\n",
      "Epoch 3, Batch 0, Loss: 0.010688033886253834\n",
      "Epoch 3, Batch 1, Loss: 0.013516386970877647\n",
      "Epoch 3, Average Loss: 0.01210221042856574\n",
      "Epoch 4, Batch 0, Loss: 0.010887542739510536\n",
      "Epoch 4, Batch 1, Loss: 0.009350590407848358\n",
      "Epoch 4, Average Loss: 0.010119066573679447\n",
      "Epoch 5, Batch 0, Loss: 0.01015101931989193\n",
      "Epoch 5, Batch 1, Loss: 0.008521205745637417\n",
      "Epoch 5, Average Loss: 0.009336112532764673\n",
      "Epoch 6, Batch 0, Loss: 0.008948286063969135\n",
      "Epoch 6, Batch 1, Loss: 0.009673788212239742\n",
      "Epoch 6, Average Loss: 0.009311037138104439\n",
      "Epoch 7, Batch 0, Loss: 0.0082356883212924\n",
      "Epoch 7, Batch 1, Loss: 0.00917840376496315\n",
      "Epoch 7, Average Loss: 0.008707046043127775\n",
      "Epoch 8, Batch 0, Loss: 0.007733088918030262\n",
      "Epoch 8, Batch 1, Loss: 0.008255035616457462\n",
      "Epoch 8, Average Loss: 0.007994062267243862\n",
      "Epoch 9, Batch 0, Loss: 0.007413989864289761\n",
      "Epoch 9, Batch 1, Loss: 0.006936987861990929\n",
      "Epoch 9, Average Loss: 0.007175488863140345\n",
      "Epoch 10, Batch 0, Loss: 0.006772084627300501\n",
      "Epoch 10, Batch 1, Loss: 0.007176403887569904\n",
      "Epoch 10, Average Loss: 0.006974244257435203\n",
      "Epoch 11, Batch 0, Loss: 0.006291128695011139\n",
      "Epoch 11, Batch 1, Loss: 0.0070076631382107735\n",
      "Epoch 11, Average Loss: 0.006649395916610956\n",
      "Epoch 12, Batch 0, Loss: 0.006055417470633984\n",
      "Epoch 12, Batch 1, Loss: 0.006170389708131552\n",
      "Epoch 12, Average Loss: 0.006112903589382768\n",
      "Epoch 13, Batch 0, Loss: 0.005641607567667961\n",
      "Epoch 13, Batch 1, Loss: 0.006243162788450718\n",
      "Epoch 13, Average Loss: 0.0059423851780593395\n",
      "Epoch 14, Batch 0, Loss: 0.0055992393754422665\n",
      "Epoch 14, Batch 1, Loss: 0.004976154770702124\n",
      "Epoch 14, Average Loss: 0.005287697073072195\n",
      "Epoch 15, Batch 0, Loss: 0.005112193059176207\n",
      "Epoch 15, Batch 1, Loss: 0.0056601520627737045\n",
      "Epoch 15, Average Loss: 0.0053861725609749556\n",
      "Epoch 16, Batch 0, Loss: 0.005009541288018227\n",
      "Epoch 16, Batch 1, Loss: 0.00494282366707921\n",
      "Epoch 16, Average Loss: 0.0049761824775487185\n",
      "Epoch 17, Batch 0, Loss: 0.005018531810492277\n",
      "Epoch 17, Batch 1, Loss: 0.0038606603629887104\n",
      "Epoch 17, Average Loss: 0.004439596086740494\n",
      "Epoch 18, Batch 0, Loss: 0.004595580045133829\n",
      "Epoch 18, Batch 1, Loss: 0.004594358615577221\n",
      "Epoch 18, Average Loss: 0.004594969330355525\n",
      "Epoch 19, Batch 0, Loss: 0.004554150626063347\n",
      "Epoch 19, Batch 1, Loss: 0.00397985614836216\n",
      "Epoch 19, Average Loss: 0.004267003387212753\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Autoencoder Models\n",
    "class AE1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE1, self).__init__()\n",
    "        self.encoder = nn.Linear(512, 16)\n",
    "        self.decoder = nn.Linear(16, 512)\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.encoder(x))\n",
    "        x = F.tanh(self.decoder(x))\n",
    "        return x\n",
    "class AE2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE2, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Linear(512, 128)\n",
    "        self.enc2 = nn.Linear(128, 64)\n",
    "        self.enc3 = nn.Linear(64, 16)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec1 = nn.Linear(16, 64)\n",
    "        self.dec2 = nn.Linear(64, 128)\n",
    "        self.dec3 = nn.Linear(128, 512)\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.enc1(x))\n",
    "        x = F.tanh(self.enc2(x))\n",
    "        x = F.tanh(self.enc3(x))\n",
    "        x = F.tanh(self.dec1(x))\n",
    "        x = F.tanh(self.dec2(x))\n",
    "        x = F.tanh(self.dec3(x))\n",
    "        return x\n",
    "class AE3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE3, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Linear(512, 384)\n",
    "        self.enc2 = nn.Linear(384, 256)\n",
    "        self.enc3 = nn.Linear(256, 128)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec1 = nn.Linear(128, 256)\n",
    "        self.dec2 = nn.Linear(256, 384)\n",
    "        self.dec3 = nn.Linear(384, 512)\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.enc1(x))\n",
    "        x = F.tanh(self.enc2(x))\n",
    "        x = F.tanh(self.enc3(x))\n",
    "        x = F.tanh(self.dec1(x))\n",
    "        x = F.tanh(self.dec2(x))\n",
    "        x = F.tanh(self.dec3(x))\n",
    "        return x\n",
    "# Custom Audio Dataset\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audio_files, signal_length, frame_length, overlap):\n",
    "        \n",
    "        self.audio_files = audio_files\n",
    "        self.signal_length = signal_length\n",
    "        self.frame_length = frame_length\n",
    "        self.overlap = overlap\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_files[idx]\n",
    "        waveform, _ = torchaudio.load(audio_path)\n",
    "        # Truncate or Zero-pad the signal\n",
    "        waveform = self._adjust_length(waveform)\n",
    "        # Normalize the signal\n",
    "        waveform = self._normalize(waveform)\n",
    "        # Segment into frames\n",
    "        frames = self._segment_into_frames(waveform)\n",
    "        return frames\n",
    "    def _adjust_length(self, waveform):\n",
    "        if waveform.shape[1] > self.signal_length:\n",
    "            return waveform[:, :self.signal_length]\n",
    "        elif waveform.shape[1] < self.signal_length:\n",
    "            padding = self.signal_length - waveform.shape[1]\n",
    "            return F.pad(waveform, (0, padding))\n",
    "        else:\n",
    "            return waveform\n",
    "    def _normalize(self, waveform):\n",
    "        max_val = torch.max(torch.abs(waveform))\n",
    "        if max_val > 0:\n",
    "            return waveform / max_val\n",
    "        return waveform\n",
    "    def _segment_into_frames(self, waveform):\n",
    "        step = self.frame_length - self.overlap\n",
    "        num_frames = 1 + (waveform.shape[1] - self.frame_length) // step\n",
    "        frames = torch.zeros((num_frames, self.frame_length))\n",
    "        for i in range(num_frames):\n",
    "            start = i * step\n",
    "            end = start + self.frame_length\n",
    "            frames[i] = waveform[0, start:end]\n",
    "        return frames\n",
    "# Training Function\n",
    "def train(model, train_loader, epochs, device):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}\")\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch}, Average Loss: {avg_loss}\")\n",
    "# Testing Function\n",
    "def test(model, test_loader, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    total_snr = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            reconstructed = model(data)\n",
    "            original_signal = overlap_add(data, overlap)\n",
    "            reconstructed_signal = overlap_add(reconstructed, overlap)\n",
    "            snr = calculate_snr(original_signal, reconstructed_signal)\n",
    "            print(f\"Signal {count}, SNR: {snr}\")\n",
    "            total_snr += snr\n",
    "            count += 1\n",
    "    avg_snr = total_snr / count\n",
    "    print(f\"Average SNR: {avg_snr}\")\n",
    "# Helper Functions\n",
    "def calculate_snr(original, reconstructed):\n",
    "    noise = original - reconstructed\n",
    "    signal_power = torch.mean(original ** 2)\n",
    "    noise_power = torch.mean(noise ** 2)\n",
    "    snr = 10 * torch.log10(signal_power / noise_power)\n",
    "    return snr.item()\n",
    "def overlap_add(frames, overlap, window_fn=torch.hann_window):\n",
    "    frame_length = frames.shape[1]\n",
    "    step = frame_length - overlap\n",
    "    signal_length = step * (frames.shape[0] - 1) + frame_length\n",
    "    signal = torch.zeros(signal_length)\n",
    "    window = window_fn(frame_length)\n",
    "    for i, frame in enumerate(frames):\n",
    "        start = i * step\n",
    "        end = start + frame_length\n",
    "        signal[start:end] += frame * window\n",
    "    return signal\n",
    "\n",
    "import os\n",
    "# Assuming a sampling rate of 16 kHz\n",
    "sampling_rate = 16000\n",
    "signal_length_seconds = 6  # 6s\n",
    "signal_length_samples = sampling_rate * signal_length_seconds  \n",
    "\n",
    "def get_audio_files(directory_path):\n",
    "    return [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.wav')]\n",
    "# Local Directory path\n",
    "directory_path = r'C:\\Kursmaterial\\Dl der Sprachsignalverarbeitung\\Computerübung 2\\signals\\Train_40'\n",
    "audio_files = get_audio_files(directory_path)\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "frame_length = 512 \n",
    "# Create dataset and data loaders\n",
    "train_dataset = AudioDataset(audio_files, signal_length_samples, frame_length, overlap=0)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# Train and test the models\n",
    "# Training AE1\n",
    "model1 = AE1()  \n",
    "device = torch.device(\"cpu\")\n",
    "epochs = 20\n",
    "train(model1, train_loader, epochs, device)\n",
    "# Training AE2\n",
    "model2 = AE2()  \n",
    "train(model2, train_loader, epochs, device)\n",
    "# Training AE3\n",
    "model3 = AE3()  \n",
    "train(model3, train_loader, epochs, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
