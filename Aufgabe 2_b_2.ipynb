{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, for each autoencoder, listen to one\n",
    "reconstructed test signal and the corresponding reference signal (for better\n",
    "comparison, choose the same test signal for all three autoencoders). What do\n",
    "you hear? Can you recognize unwanted effects? Describe your observations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "# Autoencoder Models\n",
    "class AE1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE1, self).__init__()\n",
    "        self.encoder = nn.Linear(512, 16)\n",
    "        self.decoder = nn.Linear(16, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.encoder(x))\n",
    "        x = F.tanh(self.decoder(x))\n",
    "        return x\n",
    "class AE2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE2, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Linear(512, 128)\n",
    "        self.enc2 = nn.Linear(128, 64)\n",
    "        self.enc3 = nn.Linear(64, 16)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec1 = nn.Linear(16, 64)\n",
    "        self.dec2 = nn.Linear(64, 128)\n",
    "        self.dec3 = nn.Linear(128, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.enc1(x))\n",
    "        x = F.tanh(self.enc2(x))\n",
    "        x = F.tanh(self.enc3(x))\n",
    "        x = F.tanh(self.dec1(x))\n",
    "        x = F.tanh(self.dec2(x))\n",
    "        x = F.tanh(self.dec3(x))\n",
    "        return x\n",
    "\n",
    "class AE3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE3, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Linear(512, 384)\n",
    "        self.enc2 = nn.Linear(384, 256)\n",
    "        self.enc3 = nn.Linear(256, 128)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec1 = nn.Linear(128, 256)\n",
    "        self.dec2 = nn.Linear(256, 384)\n",
    "        self.dec3 = nn.Linear(384, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.enc1(x))\n",
    "        x = F.tanh(self.enc2(x))\n",
    "        x = F.tanh(self.enc3(x))\n",
    "        x = F.tanh(self.dec1(x))\n",
    "        x = F.tanh(self.dec2(x))\n",
    "        x = F.tanh(self.dec3(x))\n",
    "        return x\n",
    "\n",
    "# Custom Audio Dataset\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audio_files, signal_length, frame_length, overlap):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_files (list): List of paths to audio files.\n",
    "            signal_length (int): Desired length of the signal in samples (La).\n",
    "            frame_length (int): Frame length in samples (LF).\n",
    "            overlap (int): Overlap of frames in samples (O).\n",
    "        \"\"\"\n",
    "        self.audio_files = audio_files\n",
    "        self.signal_length = signal_length\n",
    "        self.frame_length = frame_length\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "    \n",
    "    def _adjust_frame_length_for_testing(self, frame):\n",
    "        if frame.shape[1] < 512:\n",
    "            padding = 512 - frame.shape[1]\n",
    "            frame = F.pad(frame, (0, padding))\n",
    "        elif frame.shape[1] > 512:\n",
    "            frame = frame[:, :512]\n",
    "        return frame\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_files[idx]\n",
    "        waveform, _ = torchaudio.load(audio_path)\n",
    "\n",
    "        # Truncate or Zero-pad the signal\n",
    "        waveform = self._adjust_length(waveform)\n",
    "\n",
    "        # Normalize the signal\n",
    "        waveform = self._normalize(waveform)\n",
    "\n",
    "        # Segment into frames\n",
    "        frames = self._segment_into_frames(waveform)\n",
    "\n",
    "        # Adjust frame length for testing\n",
    "        adjusted_frames = torch.zeros((frames.shape[0], 512))\n",
    "        for i, frame in enumerate(frames):\n",
    "            adjusted_frames[i] = self._adjust_frame_length_for_testing(frame.unsqueeze(0))\n",
    "\n",
    "        return adjusted_frames\n",
    "        \n",
    "\n",
    "    def _adjust_length(self, waveform):\n",
    "        if waveform.shape[1] > self.signal_length:\n",
    "            return waveform[:, :self.signal_length]\n",
    "        elif waveform.shape[1] < self.signal_length:\n",
    "            padding = self.signal_length - waveform.shape[1]\n",
    "            return F.pad(waveform, (0, padding))\n",
    "        else:\n",
    "            return waveform\n",
    "\n",
    "    def _normalize(self, waveform):\n",
    "        max_val = torch.max(torch.abs(waveform))\n",
    "        if max_val > 0:\n",
    "            return waveform / max_val\n",
    "        return waveform\n",
    "\n",
    "    def _segment_into_frames(self, waveform):\n",
    "        step = self.frame_length - self.overlap\n",
    "        num_frames = 1 + (waveform.shape[1] - self.frame_length) // step\n",
    "        frames = torch.zeros((num_frames, self.frame_length))\n",
    "\n",
    "        for i in range(num_frames):\n",
    "            start = i * step\n",
    "            end = start + self.frame_length\n",
    "            frames[i] = waveform[0, start:end]\n",
    "\n",
    "        return frames\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, epochs, device):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}\")\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch}, Average Loss: {avg_loss}\")\n",
    "\n",
    "# Testing Function\n",
    "def test(model, test_loader, device, overlap=0):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    total_snr = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            #print(data.shape)\n",
    "            reconstructed = model(data)\n",
    "            original_signal = overlap_add(data, overlap)\n",
    "            reconstructed_signal = overlap_add(reconstructed, overlap)\n",
    "            snr = calculate_snr(original_signal, reconstructed_signal)\n",
    "            print(f\"Signal {count}, SNR: {snr}\")\n",
    "            total_snr += snr\n",
    "            count += 1\n",
    "\n",
    "    avg_snr = total_snr / count\n",
    "    print(f\"Average SNR: {avg_snr}\")\n",
    "\n",
    "# Helper Functions\n",
    "def calculate_snr(original, reconstructed):\n",
    "    noise = original - reconstructed\n",
    "    signal_power = torch.mean(original ** 2)\n",
    "    noise_power = torch.mean(noise ** 2)\n",
    "    snr = 10 * torch.log10(signal_power / noise_power)\n",
    "    return snr.item()\n",
    "\n",
    "\n",
    "\n",
    "def overlap_add(frames, overlap):\n",
    "    frames = frames.squeeze()\n",
    "    frame_length = frames.shape[1] #L\n",
    "    frame_zahl= frames.shape[0] #N\n",
    "    step = frame_length - overlap\n",
    "    signal_length = step * (frames.shape[0] - 1) + frame_length\n",
    "    signal = torch.zeros(signal_length)\n",
    "    window = torch.ones(frame_length)  # Rectangular window\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(frame_zahl):\n",
    "        start = i *step\n",
    "        end = start + frame_length\n",
    "        #print(end-start, frames[i].size(), window.size())\n",
    "        signal[start:end] += frames[i] * window\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output and save one of the reconstructed test signal for each of the autoencoder\n",
    "def test_and_save(model, test_loader, device, overlap, model_name, sampling_rate):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Process only the first batch from the test loader\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            reconstructed = model(data)\n",
    "            reconstructed_signal = overlap_add(reconstructed, overlap)\n",
    "            \n",
    "            # Save the reconstructed signal to a WAV file\n",
    "            filename = f\"{model_name}_reconstructed.wav\"\n",
    "            torchaudio.save(filename, reconstructed_signal.unsqueeze(0), sampling_rate)\n",
    "            print(f\"Reconstructed signal saved as {filename}\")\n",
    "\n",
    "            break  # Process only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing AE1\n",
      "Epoch 0, Batch 0, Loss: 0.03412506729364395\n",
      "Epoch 0, Batch 1, Loss: 0.03439036384224892\n",
      "Epoch 0, Average Loss: 0.034257715567946434\n",
      "Epoch 1, Batch 0, Loss: 0.033075522631406784\n",
      "Epoch 1, Batch 1, Loss: 0.032907553017139435\n",
      "Epoch 1, Average Loss: 0.03299153782427311\n",
      "Epoch 2, Batch 0, Loss: 0.03214782103896141\n",
      "Epoch 2, Batch 1, Loss: 0.031606096774339676\n",
      "Epoch 2, Average Loss: 0.03187695890665054\n",
      "Epoch 3, Batch 0, Loss: 0.031265150755643845\n",
      "Epoch 3, Batch 1, Loss: 0.03060995787382126\n",
      "Epoch 3, Average Loss: 0.03093755431473255\n",
      "Epoch 4, Batch 0, Loss: 0.02995428815484047\n",
      "Epoch 4, Batch 1, Loss: 0.031670816242694855\n",
      "Epoch 4, Average Loss: 0.030812552198767662\n",
      "Epoch 5, Batch 0, Loss: 0.029103389009833336\n",
      "Epoch 5, Batch 1, Loss: 0.03112940303981304\n",
      "Epoch 5, Average Loss: 0.03011639602482319\n",
      "Epoch 6, Batch 0, Loss: 0.028282586485147476\n",
      "Epoch 6, Batch 1, Loss: 0.030605904757976532\n",
      "Epoch 6, Average Loss: 0.029444245621562004\n",
      "Epoch 7, Batch 0, Loss: 0.0278303399682045\n",
      "Epoch 7, Batch 1, Loss: 0.028696518391370773\n",
      "Epoch 7, Average Loss: 0.028263429179787636\n",
      "Epoch 8, Batch 0, Loss: 0.028138596564531326\n",
      "Epoch 8, Batch 1, Loss: 0.023790268227458\n",
      "Epoch 8, Average Loss: 0.025964432395994663\n",
      "Epoch 9, Batch 0, Loss: 0.02640274353325367\n",
      "Epoch 9, Batch 1, Loss: 0.0270858034491539\n",
      "Epoch 9, Average Loss: 0.026744273491203785\n",
      "Epoch 10, Batch 0, Loss: 0.02565034292638302\n",
      "Epoch 10, Batch 1, Loss: 0.02647075615823269\n",
      "Epoch 10, Average Loss: 0.026060549542307854\n",
      "Epoch 11, Batch 0, Loss: 0.024856913834810257\n",
      "Epoch 11, Batch 1, Loss: 0.026027783751487732\n",
      "Epoch 11, Average Loss: 0.025442348793148994\n",
      "Epoch 12, Batch 0, Loss: 0.02466026321053505\n",
      "Epoch 12, Batch 1, Loss: 0.023212244734168053\n",
      "Epoch 12, Average Loss: 0.02393625397235155\n",
      "Epoch 13, Batch 0, Loss: 0.023551728576421738\n",
      "Epoch 13, Batch 1, Loss: 0.024064062163233757\n",
      "Epoch 13, Average Loss: 0.023807895369827747\n",
      "Epoch 14, Batch 0, Loss: 0.02324531599879265\n",
      "Epoch 14, Batch 1, Loss: 0.021744687110185623\n",
      "Epoch 14, Average Loss: 0.022495001554489136\n",
      "Epoch 15, Batch 0, Loss: 0.022337401285767555\n",
      "Epoch 15, Batch 1, Loss: 0.02188355103135109\n",
      "Epoch 15, Average Loss: 0.022110476158559322\n",
      "Epoch 16, Batch 0, Loss: 0.021616043522953987\n",
      "Epoch 16, Batch 1, Loss: 0.0213425625115633\n",
      "Epoch 16, Average Loss: 0.021479303017258644\n",
      "Epoch 17, Batch 0, Loss: 0.021052857860922813\n",
      "Epoch 17, Batch 1, Loss: 0.020243601873517036\n",
      "Epoch 17, Average Loss: 0.020648229867219925\n",
      "Epoch 18, Batch 0, Loss: 0.020451083779335022\n",
      "Epoch 18, Batch 1, Loss: 0.019385214895009995\n",
      "Epoch 18, Average Loss: 0.019918149337172508\n",
      "Epoch 19, Batch 0, Loss: 0.01983652077615261\n",
      "Epoch 19, Batch 1, Loss: 0.018674857914447784\n",
      "Epoch 19, Average Loss: 0.019255689345300198\n",
      "Signal 0, SNR: -2.083331346511841\n",
      "Signal 1, SNR: -2.1109671592712402\n",
      "Signal 2, SNR: -1.2476136684417725\n",
      "Signal 3, SNR: -1.7293392419815063\n",
      "Signal 4, SNR: -3.87483811378479\n",
      "Signal 5, SNR: -1.9436520338058472\n",
      "Signal 6, SNR: -2.0363192558288574\n",
      "Signal 7, SNR: -3.9565558433532715\n",
      "Signal 8, SNR: -2.3299660682678223\n",
      "Signal 9, SNR: -1.872396469116211\n",
      "Signal 10, SNR: -1.6999690532684326\n",
      "Signal 11, SNR: -1.9792698621749878\n",
      "Signal 12, SNR: -1.5314973592758179\n",
      "Signal 13, SNR: -1.8081415891647339\n",
      "Signal 14, SNR: -2.3075146675109863\n",
      "Signal 15, SNR: -6.044565200805664\n",
      "Average SNR: -2.4097460582852364\n",
      "Reconstructed signal saved as AE1_reconstructed.wav\n",
      "Training and Testing AE2\n",
      "Epoch 0, Batch 0, Loss: 0.018540820106863976\n",
      "Epoch 0, Batch 1, Loss: 0.01712234690785408\n",
      "Epoch 0, Average Loss: 0.017831583507359028\n",
      "Epoch 1, Batch 0, Loss: 0.015340306796133518\n",
      "Epoch 1, Batch 1, Loss: 0.014340209774672985\n",
      "Epoch 1, Average Loss: 0.014840258285403252\n",
      "Epoch 2, Batch 0, Loss: 0.013732771389186382\n",
      "Epoch 2, Batch 1, Loss: 0.013211831450462341\n",
      "Epoch 2, Average Loss: 0.013472301419824362\n",
      "Epoch 3, Batch 0, Loss: 0.012950673699378967\n",
      "Epoch 3, Batch 1, Loss: 0.012439756654202938\n",
      "Epoch 3, Average Loss: 0.012695215176790953\n",
      "Epoch 4, Batch 0, Loss: 0.012851563282310963\n",
      "Epoch 4, Batch 1, Loss: 0.01085465494543314\n",
      "Epoch 4, Average Loss: 0.011853109113872051\n",
      "Epoch 5, Batch 0, Loss: 0.012336029671132565\n",
      "Epoch 5, Batch 1, Loss: 0.011889098212122917\n",
      "Epoch 5, Average Loss: 0.01211256394162774\n",
      "Epoch 6, Batch 0, Loss: 0.012228001840412617\n",
      "Epoch 6, Batch 1, Loss: 0.011624720878899097\n",
      "Epoch 6, Average Loss: 0.011926361359655857\n",
      "Epoch 7, Batch 0, Loss: 0.012066670693457127\n",
      "Epoch 7, Batch 1, Loss: 0.01162765920162201\n",
      "Epoch 7, Average Loss: 0.011847164947539568\n",
      "Epoch 8, Batch 0, Loss: 0.011162782087922096\n",
      "Epoch 8, Batch 1, Loss: 0.014631550759077072\n",
      "Epoch 8, Average Loss: 0.012897166423499584\n",
      "Epoch 9, Batch 0, Loss: 0.012153742834925652\n",
      "Epoch 9, Batch 1, Loss: 0.010094454512000084\n",
      "Epoch 9, Average Loss: 0.011124098673462868\n",
      "Epoch 10, Batch 0, Loss: 0.011737402528524399\n",
      "Epoch 10, Batch 1, Loss: 0.011139009147882462\n",
      "Epoch 10, Average Loss: 0.01143820583820343\n",
      "Epoch 11, Batch 0, Loss: 0.011352578178048134\n",
      "Epoch 11, Batch 1, Loss: 0.012028777040541172\n",
      "Epoch 11, Average Loss: 0.011690677609294653\n",
      "Epoch 12, Batch 0, Loss: 0.011800786480307579\n",
      "Epoch 12, Batch 1, Loss: 0.009574227035045624\n",
      "Epoch 12, Average Loss: 0.010687506757676601\n",
      "Epoch 13, Batch 0, Loss: 0.011055470444262028\n",
      "Epoch 13, Batch 1, Loss: 0.011821319349110126\n",
      "Epoch 13, Average Loss: 0.011438394896686077\n",
      "Epoch 14, Batch 0, Loss: 0.010870635509490967\n",
      "Epoch 14, Batch 1, Loss: 0.011815101839601994\n",
      "Epoch 14, Average Loss: 0.01134286867454648\n",
      "Epoch 15, Batch 0, Loss: 0.011276195757091045\n",
      "Epoch 15, Batch 1, Loss: 0.009424312971532345\n",
      "Epoch 15, Average Loss: 0.010350254364311695\n",
      "Epoch 16, Batch 0, Loss: 0.011229071766138077\n",
      "Epoch 16, Batch 1, Loss: 0.008846957236528397\n",
      "Epoch 16, Average Loss: 0.010038014501333237\n",
      "Epoch 17, Batch 0, Loss: 0.010508690029382706\n",
      "Epoch 17, Batch 1, Loss: 0.010942487046122551\n",
      "Epoch 17, Average Loss: 0.010725588537752628\n",
      "Epoch 18, Batch 0, Loss: 0.010398021899163723\n",
      "Epoch 18, Batch 1, Loss: 0.010640166699886322\n",
      "Epoch 18, Average Loss: 0.010519094299525023\n",
      "Epoch 19, Batch 0, Loss: 0.010689846239984035\n",
      "Epoch 19, Batch 1, Loss: 0.008736061863601208\n",
      "Epoch 19, Average Loss: 0.009712954051792622\n",
      "Signal 0, SNR: 0.6987509727478027\n",
      "Signal 1, SNR: 0.3779867887496948\n",
      "Signal 2, SNR: 0.7958480715751648\n",
      "Signal 3, SNR: 0.5147554874420166\n",
      "Signal 4, SNR: 0.4644591212272644\n",
      "Signal 5, SNR: 1.1935205459594727\n",
      "Signal 6, SNR: 0.9701036214828491\n",
      "Signal 7, SNR: 0.43244999647140503\n",
      "Signal 8, SNR: 0.3839963674545288\n",
      "Signal 9, SNR: 0.8850983381271362\n",
      "Signal 10, SNR: 0.9381243586540222\n",
      "Signal 11, SNR: 1.0487867593765259\n",
      "Signal 12, SNR: 0.9385510683059692\n",
      "Signal 13, SNR: 0.8208993077278137\n",
      "Signal 14, SNR: 0.7333269119262695\n",
      "Signal 15, SNR: 0.3784262537956238\n",
      "Average SNR: 0.7234427481889725\n",
      "Reconstructed signal saved as AE2_reconstructed.wav\n",
      "Training and Testing AE3\n",
      "Epoch 0, Batch 0, Loss: 0.013877206481993198\n",
      "Epoch 0, Batch 1, Loss: 0.013342647813260555\n",
      "Epoch 0, Average Loss: 0.013609927147626877\n",
      "Epoch 1, Batch 0, Loss: 0.012081882916390896\n",
      "Epoch 1, Batch 1, Loss: 0.01293855719268322\n",
      "Epoch 1, Average Loss: 0.012510220054537058\n",
      "Epoch 2, Batch 0, Loss: 0.011845126748085022\n",
      "Epoch 2, Batch 1, Loss: 0.011710249818861485\n",
      "Epoch 2, Average Loss: 0.011777688283473253\n",
      "Epoch 3, Batch 0, Loss: 0.011533231474459171\n",
      "Epoch 3, Batch 1, Loss: 0.010250704362988472\n",
      "Epoch 3, Average Loss: 0.010891967918723822\n",
      "Epoch 4, Batch 0, Loss: 0.01072798203676939\n",
      "Epoch 4, Batch 1, Loss: 0.010121550410985947\n",
      "Epoch 4, Average Loss: 0.010424766223877668\n",
      "Epoch 5, Batch 0, Loss: 0.00993775762617588\n",
      "Epoch 5, Batch 1, Loss: 0.009742023423314095\n",
      "Epoch 5, Average Loss: 0.009839890524744987\n",
      "Epoch 6, Batch 0, Loss: 0.009453871287405491\n",
      "Epoch 6, Batch 1, Loss: 0.008379710838198662\n",
      "Epoch 6, Average Loss: 0.008916791062802076\n",
      "Epoch 7, Batch 0, Loss: 0.008787372149527073\n",
      "Epoch 7, Batch 1, Loss: 0.007965012453496456\n",
      "Epoch 7, Average Loss: 0.008376192301511765\n",
      "Epoch 8, Batch 0, Loss: 0.00837892945855856\n",
      "Epoch 8, Batch 1, Loss: 0.006801920011639595\n",
      "Epoch 8, Average Loss: 0.007590424735099077\n",
      "Epoch 9, Batch 0, Loss: 0.00766309630125761\n",
      "Epoch 9, Batch 1, Loss: 0.007092205807566643\n",
      "Epoch 9, Average Loss: 0.0073776510544121265\n",
      "Epoch 10, Batch 0, Loss: 0.00717307860031724\n",
      "Epoch 10, Batch 1, Loss: 0.00678589753806591\n",
      "Epoch 10, Average Loss: 0.006979488069191575\n",
      "Epoch 11, Batch 0, Loss: 0.0068410951644182205\n",
      "Epoch 11, Batch 1, Loss: 0.0060221971943974495\n",
      "Epoch 11, Average Loss: 0.006431646179407835\n",
      "Epoch 12, Batch 0, Loss: 0.006347064860165119\n",
      "Epoch 12, Batch 1, Loss: 0.005974348168820143\n",
      "Epoch 12, Average Loss: 0.006160706514492631\n",
      "Epoch 13, Batch 0, Loss: 0.00601981719955802\n",
      "Epoch 13, Batch 1, Loss: 0.005558717530220747\n",
      "Epoch 13, Average Loss: 0.005789267364889383\n",
      "Epoch 14, Batch 0, Loss: 0.005712005775421858\n",
      "Epoch 14, Batch 1, Loss: 0.005258846562355757\n",
      "Epoch 14, Average Loss: 0.005485426168888807\n",
      "Epoch 15, Batch 0, Loss: 0.005545489955693483\n",
      "Epoch 15, Batch 1, Loss: 0.00453731557354331\n",
      "Epoch 15, Average Loss: 0.005041402764618397\n",
      "Epoch 16, Batch 0, Loss: 0.005089314188808203\n",
      "Epoch 16, Batch 1, Loss: 0.0050777243450284\n",
      "Epoch 16, Average Loss: 0.005083519266918302\n",
      "Epoch 17, Batch 0, Loss: 0.00506803160533309\n",
      "Epoch 17, Batch 1, Loss: 0.00401951652020216\n",
      "Epoch 17, Average Loss: 0.004543774062767625\n",
      "Epoch 18, Batch 0, Loss: 0.004696434363722801\n",
      "Epoch 18, Batch 1, Loss: 0.004489799030125141\n",
      "Epoch 18, Average Loss: 0.004593116696923971\n",
      "Epoch 19, Batch 0, Loss: 0.004606079310178757\n",
      "Epoch 19, Batch 1, Loss: 0.004004360642284155\n",
      "Epoch 19, Average Loss: 0.004305219976231456\n",
      "Signal 0, SNR: 2.919694423675537\n",
      "Signal 1, SNR: 1.5306891202926636\n",
      "Signal 2, SNR: 4.997000694274902\n",
      "Signal 3, SNR: 2.7565674781799316\n",
      "Signal 4, SNR: 3.4579997062683105\n",
      "Signal 5, SNR: 5.507584095001221\n",
      "Signal 6, SNR: 3.7994537353515625\n",
      "Signal 7, SNR: 2.419304609298706\n",
      "Signal 8, SNR: 1.619882583618164\n",
      "Signal 9, SNR: 6.749136447906494\n",
      "Signal 10, SNR: 6.099876403808594\n",
      "Signal 11, SNR: 6.278231143951416\n",
      "Signal 12, SNR: 6.704291343688965\n",
      "Signal 13, SNR: 4.837937831878662\n",
      "Signal 14, SNR: 4.353169918060303\n",
      "Signal 15, SNR: 2.530564069747925\n",
      "Average SNR: 4.16008647531271\n",
      "Reconstructed signal saved as AE3_reconstructed.wav\n"
     ]
    }
   ],
   "source": [
    "# Assuming a sampling rate of 16 kHz\n",
    "sampling_rate = 16000\n",
    "signal_length_seconds = 6  # 6 seconds\n",
    "signal_length_samples = sampling_rate * signal_length_seconds  # Convert to samples\n",
    "\n",
    "# Function to get audio file paths\n",
    "def get_audio_files(directory_path):\n",
    "    return [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.wav')]\n",
    "\n",
    "# Directory path for training data\n",
    "train_directory_path = r'C:\\Kursmaterial\\Dl der Sprachsignalverarbeitung\\Computerübung 2\\signals\\Train_40'\n",
    "train_audio_files = get_audio_files(train_directory_path)\n",
    "\n",
    "# Directory path for test data\n",
    "test_directory_path = r'C:\\Kursmaterial\\Dl der Sprachsignalverarbeitung\\Computerübung 2\\signals\\Test_16'\n",
    "test_audio_files = get_audio_files(test_directory_path)\n",
    "\n",
    "# Training and testing data loaders\n",
    "frame_length = 512\n",
    "frame_length_test = 512\n",
    "train_dataset = AudioDataset(train_audio_files, signal_length_samples, frame_length, overlap=0)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = AudioDataset(test_audio_files, signal_length_samples, frame_length_test, overlap=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to train and test a model\n",
    "def train_and_test_model(model_class, train_loader, test_loader, device, model_name):\n",
    "    model = model_class().to(device)\n",
    "    train(model, train_loader, 20, device)  # Corrected the order of arguments\n",
    "    test(model, test_loader, device)\n",
    "    test_and_save(model, test_loader, device, 0, model_name,  sampling_rate)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Train and test AE1\n",
    "print(\"Training and Testing AE1\")\n",
    "train_and_test_model(AE1, train_loader, test_loader, device, \"AE1\")\n",
    "\n",
    "# Train and test AE2\n",
    "print(\"Training and Testing AE2\")\n",
    "train_and_test_model(AE2, train_loader, test_loader, device, \"AE2\")\n",
    "\n",
    "# Train and test AE3\n",
    "print(\"Training and Testing AE3\")\n",
    "train_and_test_model(AE3, train_loader, test_loader, device, \"AE3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstruced signals are mixtured with noisy, which are difficult to hear a clear Voice compared with the corresponding reference signal. Besides, in Comparision with the 3 reconstruced signals for 3 Autoencoders, the third voice is clearest, that is because of a larger SNR, which is due to more convolutionlayers in Autoencoderstructur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
