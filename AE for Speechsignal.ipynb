{
 "cells": [
  
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "# Autoencoder Models\n",
    "\n",
    "\n",
    "class AE3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE3, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Linear(512, 384)\n",
    "        self.enc2 = nn.Linear(384, 256)\n",
    "        self.enc3 = nn.Linear(256, 128)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec1 = nn.Linear(128, 256)\n",
    "        self.dec2 = nn.Linear(256, 384)\n",
    "        self.dec3 = nn.Linear(384, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.enc1(x))\n",
    "        x = F.tanh(self.enc2(x))\n",
    "        x = F.tanh(self.enc3(x))\n",
    "        x = F.tanh(self.dec1(x))\n",
    "        x = F.tanh(self.dec2(x))\n",
    "        x = F.tanh(self.dec3(x))\n",
    "        return x\n",
    "\n",
    "# Custom Audio Dataset\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audio_files, signal_length, frame_length, overlap):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_files (list): List of paths to audio files.\n",
    "            signal_length (int): Desired length of the signal in samples (La).\n",
    "            frame_length (int): Frame length in samples (LF).\n",
    "            overlap (int): Overlap of frames in samples (O).\n",
    "        \"\"\"\n",
    "        self.audio_files = audio_files\n",
    "        self.signal_length = signal_length\n",
    "        self.frame_length = frame_length\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "    \n",
    "    def _adjust_frame_length_for_testing(self, frame):\n",
    "        if frame.shape[1] < 512:\n",
    "            padding = 512 - frame.shape[1]\n",
    "            frame = F.pad(frame, (0, padding))\n",
    "        elif frame.shape[1] > 512:\n",
    "            frame = frame[:, :512]\n",
    "        return frame\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_files[idx]\n",
    "        waveform, _ = torchaudio.load(audio_path)\n",
    "\n",
    "        # Truncate or Zero-pad the signal\n",
    "        waveform = self._adjust_length(waveform)\n",
    "\n",
    "        # Normalize the signal\n",
    "        waveform = self._normalize(waveform)\n",
    "\n",
    "        # Segment into frames\n",
    "        frames = self._segment_into_frames(waveform)\n",
    "\n",
    "        # Adjust frame length for testing\n",
    "        adjusted_frames = torch.zeros((frames.shape[0], 512))\n",
    "        for i, frame in enumerate(frames):\n",
    "            adjusted_frames[i] = self._adjust_frame_length_for_testing(frame.unsqueeze(0))\n",
    "\n",
    "        return adjusted_frames\n",
    "        \n",
    "\n",
    "    def _adjust_length(self, waveform):\n",
    "        if waveform.shape[1] > self.signal_length:\n",
    "            return waveform[:, :self.signal_length]\n",
    "        elif waveform.shape[1] < self.signal_length:\n",
    "            padding = self.signal_length - waveform.shape[1]\n",
    "            return F.pad(waveform, (0, padding))\n",
    "        else:\n",
    "            return waveform\n",
    "\n",
    "    def _normalize(self, waveform):\n",
    "        max_val = torch.max(torch.abs(waveform))\n",
    "        if max_val > 0:\n",
    "            return waveform / max_val\n",
    "        return waveform\n",
    "\n",
    "    def _segment_into_frames(self, waveform):\n",
    "        step = self.frame_length - self.overlap\n",
    "        num_frames = 1 + (waveform.shape[1] - self.frame_length) // step\n",
    "        frames = torch.zeros((num_frames, self.frame_length))\n",
    "\n",
    "        for i in range(num_frames):\n",
    "            start = i * step\n",
    "            end = start + self.frame_length\n",
    "            frames[i] = waveform[0, start:end]\n",
    "\n",
    "        return frames\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, validation_loader, epochs, device, patience):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            \n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}\")\n",
    "\n",
    "        avg_loss_train = train_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch}, Average Train Loss: {avg_loss_train}\")\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in validation_loader:\n",
    "                data = data.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, data)\n",
    "                validation_loss += loss.item()\n",
    "        avg_validation_loss = validation_loss / len(validation_loader)\n",
    "        print(f\"Epoch {epoch}, Validation Loss: {avg_validation_loss}\")\n",
    "        \n",
    "        #early stopping, checking if there are no improved loss\n",
    "        if avg_validation_loss < best_val_loss:\n",
    "            best_val_loss = avg_validation_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve == patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"continue training\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing Function\n",
    "def test(model, test_loader, device, overlap=0):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    total_snr = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            #print(data.shape)\n",
    "            reconstructed = model(data)\n",
    "            original_signal = overlap_add(data, overlap)\n",
    "            reconstructed_signal = overlap_add(reconstructed, overlap)\n",
    "            snr = calculate_snr(original_signal, reconstructed_signal)\n",
    "            print(f\"Signal {count}, SNR: {snr}\")\n",
    "            total_snr += snr\n",
    "            count += 1\n",
    "\n",
    "    avg_snr = total_snr / count\n",
    "    print(f\"Average SNR: {avg_snr}\")\n",
    "\n",
    "# Helper Functions\n",
    "def calculate_snr(original, reconstructed):\n",
    "    noise = original - reconstructed\n",
    "    signal_power = torch.mean(original ** 2)\n",
    "    noise_power = torch.mean(noise ** 2)\n",
    "    snr = 10 * torch.log10(signal_power / noise_power)\n",
    "    return snr.item()\n",
    "\n",
    "\n",
    "\n",
    "def overlap_add(frames, overlap):\n",
    "    frames = frames.squeeze()\n",
    "    frame_length = frames.shape[1] #L\n",
    "    frame_zahl= frames.shape[0] #N\n",
    "    step = frame_length - overlap\n",
    "    signal_length = step * (frames.shape[0] - 1) + frame_length\n",
    "    signal = torch.zeros(signal_length)\n",
    "    window = torch.hann_window(frame_length)  # Hann Rectangular window\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(frame_zahl):\n",
    "        start = i *step\n",
    "        end = start + frame_length\n",
    "        #print(end-start, frames[i].size(), window.size())\n",
    "        signal[start:end] += frames[i] * window\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output and save one of the reconstructed test signal for each of the autoencoder\n",
    "def test_and_save(model, test_loader, device, overlap, model_name, sampling_rate):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Process only the first batch from the test loader\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            reconstructed = model(data)\n",
    "            reconstructed_signal = overlap_add(reconstructed, overlap)\n",
    "            \n",
    "            # Save the reconstructed signal to a WAV file\n",
    "            filename = f\"{model_name}_reconstructed.wav\"\n",
    "            torchaudio.save(filename, reconstructed_signal.unsqueeze(0), sampling_rate)\n",
    "            print(f\"Reconstructed signal saved as {filename}\")\n",
    "\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing AE3\n",
      "Epoch 0, Batch 0, Loss: 0.014283169992268085\n",
      "Epoch 0, Batch 1, Loss: 0.011900583282113075\n",
      "Epoch 0, Average Train Loss: 0.01309187663719058\n",
      "Epoch 0, Validation Loss: 0.011883572209626436\n",
      "continue training\n",
      "Epoch 1, Batch 0, Loss: 0.012081695720553398\n",
      "Epoch 1, Batch 1, Loss: 0.013045878149569035\n",
      "Epoch 1, Average Train Loss: 0.012563786935061216\n",
      "Epoch 1, Validation Loss: 0.011468248907476664\n",
      "continue training\n",
      "Epoch 2, Batch 0, Loss: 0.012380347587168217\n",
      "Epoch 2, Batch 1, Loss: 0.009737769141793251\n",
      "Epoch 2, Average Train Loss: 0.011059058364480734\n",
      "Epoch 2, Validation Loss: 0.010554165113717318\n",
      "continue training\n",
      "Epoch 3, Batch 0, Loss: 0.01156557910144329\n",
      "Epoch 3, Batch 1, Loss: 0.010307559743523598\n",
      "Epoch 3, Average Train Loss: 0.010936569422483444\n",
      "Epoch 3, Validation Loss: 0.010547532700002193\n",
      "continue training\n",
      "Epoch 4, Batch 0, Loss: 0.010056394152343273\n",
      "Epoch 4, Batch 1, Loss: 0.012973006814718246\n",
      "Epoch 4, Average Train Loss: 0.01151470048353076\n",
      "Epoch 4, Validation Loss: 0.010728985071182251\n",
      "continue training\n",
      "Epoch 5, Batch 0, Loss: 0.010249064303934574\n",
      "Epoch 5, Batch 1, Loss: 0.008876670151948929\n",
      "Epoch 5, Average Train Loss: 0.009562867227941751\n",
      "Epoch 5, Validation Loss: 0.009803110267966986\n",
      "continue training\n",
      "Epoch 6, Batch 0, Loss: 0.009421010501682758\n",
      "Epoch 6, Batch 1, Loss: 0.008696886710822582\n",
      "Epoch 6, Average Train Loss: 0.00905894860625267\n",
      "Epoch 6, Validation Loss: 0.008565802592784166\n",
      "continue training\n",
      "Epoch 7, Batch 0, Loss: 0.00845279823988676\n",
      "Epoch 7, Batch 1, Loss: 0.009340164251625538\n",
      "Epoch 7, Average Train Loss: 0.00889648124575615\n",
      "Epoch 7, Validation Loss: 0.00799852004274726\n",
      "continue training\n",
      "Epoch 8, Batch 0, Loss: 0.008051144890487194\n",
      "Epoch 8, Batch 1, Loss: 0.008033274672925472\n",
      "Epoch 8, Average Train Loss: 0.008042209781706333\n",
      "Epoch 8, Validation Loss: 0.007888615597039461\n",
      "continue training\n",
      "Epoch 9, Batch 0, Loss: 0.0076532973907887936\n",
      "Epoch 9, Batch 1, Loss: 0.007026473060250282\n",
      "Epoch 9, Average Train Loss: 0.007339885225519538\n",
      "Epoch 9, Validation Loss: 0.007138526765629649\n",
      "continue training\n",
      "Epoch 10, Batch 0, Loss: 0.006827866192907095\n",
      "Epoch 10, Batch 1, Loss: 0.00792445708066225\n",
      "Epoch 10, Average Train Loss: 0.007376161636784673\n",
      "Epoch 10, Validation Loss: 0.006815459579229355\n",
      "continue training\n",
      "Epoch 11, Batch 0, Loss: 0.006463600322604179\n",
      "Epoch 11, Batch 1, Loss: 0.007206036243587732\n",
      "Epoch 11, Average Train Loss: 0.006834818283095956\n",
      "Epoch 11, Validation Loss: 0.0060796188190579414\n",
      "continue training\n",
      "Epoch 12, Batch 0, Loss: 0.006384375039488077\n",
      "Epoch 12, Batch 1, Loss: 0.0056495144963264465\n",
      "Epoch 12, Average Train Loss: 0.006016944767907262\n",
      "Epoch 12, Validation Loss: 0.005637902533635497\n",
      "continue training\n",
      "Epoch 13, Batch 0, Loss: 0.005878949537873268\n",
      "Epoch 13, Batch 1, Loss: 0.005973469000309706\n",
      "Epoch 13, Average Train Loss: 0.005926209269091487\n",
      "Epoch 13, Validation Loss: 0.005697306944057345\n",
      "continue training\n",
      "Epoch 14, Batch 0, Loss: 0.0056748464703559875\n",
      "Epoch 14, Batch 1, Loss: 0.00528671545907855\n",
      "Epoch 14, Average Train Loss: 0.005480780964717269\n",
      "Epoch 14, Validation Loss: 0.005410460522398353\n",
      "continue training\n",
      "Epoch 15, Batch 0, Loss: 0.005227117799222469\n",
      "Epoch 15, Batch 1, Loss: 0.005790551193058491\n",
      "Epoch 15, Average Train Loss: 0.00550883449614048\n",
      "Epoch 15, Validation Loss: 0.005070884013548493\n",
      "continue training\n",
      "Epoch 16, Batch 0, Loss: 0.0052036927081644535\n",
      "Epoch 16, Batch 1, Loss: 0.004676442593336105\n",
      "Epoch 16, Average Train Loss: 0.004940067650750279\n",
      "Epoch 16, Validation Loss: 0.0047643245197832584\n",
      "continue training\n",
      "Epoch 17, Batch 0, Loss: 0.005168289877474308\n",
      "Epoch 17, Batch 1, Loss: 0.00380842131562531\n",
      "Epoch 17, Average Train Loss: 0.004488355596549809\n",
      "Epoch 17, Validation Loss: 0.004918904975056648\n",
      "continue training\n",
      "Epoch 18, Batch 0, Loss: 0.004635503049939871\n",
      "Epoch 18, Batch 1, Loss: 0.005057340022176504\n",
      "Epoch 18, Average Train Loss: 0.0048464215360581875\n",
      "Epoch 18, Validation Loss: 0.004496768116950989\n",
      "continue training\n",
      "Epoch 19, Batch 0, Loss: 0.004593426361680031\n",
      "Epoch 19, Batch 1, Loss: 0.004350715782493353\n",
      "Epoch 19, Average Train Loss: 0.004472071072086692\n",
      "Epoch 19, Validation Loss: 0.004113403847441077\n",
      "continue training\n",
      "Epoch 20, Batch 0, Loss: 0.0045510558411479\n",
      "Epoch 20, Batch 1, Loss: 0.003728544106706977\n",
      "Epoch 20, Average Train Loss: 0.004139799973927438\n",
      "Epoch 20, Validation Loss: 0.004206324927508831\n",
      "continue training\n",
      "Epoch 21, Batch 0, Loss: 0.00424114940688014\n",
      "Epoch 21, Batch 1, Loss: 0.004296015482395887\n",
      "Epoch 21, Average Train Loss: 0.004268582444638014\n",
      "Epoch 21, Validation Loss: 0.00399078824557364\n",
      "continue training\n",
      "Epoch 22, Batch 0, Loss: 0.004355877637863159\n",
      "Epoch 22, Batch 1, Loss: 0.00329416966997087\n",
      "Epoch 22, Average Train Loss: 0.0038250236539170146\n",
      "Epoch 22, Validation Loss: 0.003874946036376059\n",
      "continue training\n",
      "Epoch 23, Batch 0, Loss: 0.004029512405395508\n",
      "Epoch 23, Batch 1, Loss: 0.004100190941244364\n",
      "Epoch 23, Average Train Loss: 0.004064851673319936\n",
      "Epoch 23, Validation Loss: 0.0039111776277422905\n",
      "continue training\n",
      "Epoch 24, Batch 0, Loss: 0.004159309435635805\n",
      "Epoch 24, Batch 1, Loss: 0.003095195861533284\n",
      "Epoch 24, Average Train Loss: 0.0036272526485845447\n",
      "Epoch 24, Validation Loss: 0.003846206935122609\n",
      "continue training\n",
      "Epoch 25, Batch 0, Loss: 0.00395291019231081\n",
      "Epoch 25, Batch 1, Loss: 0.003448733128607273\n",
      "Epoch 25, Average Train Loss: 0.0037008216604590416\n",
      "Epoch 25, Validation Loss: 0.0036594970151782036\n",
      "continue training\n",
      "Epoch 26, Batch 0, Loss: 0.0037186448462307453\n",
      "Epoch 26, Batch 1, Loss: 0.003950709011405706\n",
      "Epoch 26, Average Train Loss: 0.003834676928818226\n",
      "Epoch 26, Validation Loss: 0.003975754836574197\n",
      "continue training\n",
      "Epoch 27, Batch 0, Loss: 0.0035636390093714\n",
      "Epoch 27, Batch 1, Loss: 0.004150318447500467\n",
      "Epoch 27, Average Train Loss: 0.0038569787284359336\n",
      "Epoch 27, Validation Loss: 0.003924575401470065\n",
      "continue training\n",
      "Epoch 28, Batch 0, Loss: 0.003652081824839115\n",
      "Epoch 28, Batch 1, Loss: 0.0034036613069474697\n",
      "Epoch 28, Average Train Loss: 0.0035278715658932924\n",
      "Epoch 28, Validation Loss: 0.003834244329482317\n",
      "continue training\n",
      "Epoch 29, Batch 0, Loss: 0.003293223911896348\n",
      "Epoch 29, Batch 1, Loss: 0.004488205537199974\n",
      "Epoch 29, Average Train Loss: 0.003890714724548161\n",
      "Epoch 29, Validation Loss: 0.0034469638485461473\n",
      "continue training\n",
      "Epoch 30, Batch 0, Loss: 0.003314850153401494\n",
      "Epoch 30, Batch 1, Loss: 0.004075171425938606\n",
      "Epoch 30, Average Train Loss: 0.00369501078967005\n",
      "Epoch 30, Validation Loss: 0.003725143033079803\n",
      "continue training\n",
      "Epoch 31, Batch 0, Loss: 0.0032935081981122494\n",
      "Epoch 31, Batch 1, Loss: 0.0038518449291586876\n",
      "Epoch 31, Average Train Loss: 0.0035726765636354685\n",
      "Epoch 31, Validation Loss: 0.0031775370007380843\n",
      "continue training\n",
      "Epoch 32, Batch 0, Loss: 0.003200663486495614\n",
      "Epoch 32, Batch 1, Loss: 0.0039441995322704315\n",
      "Epoch 32, Average Train Loss: 0.003572431509383023\n",
      "Epoch 32, Validation Loss: 0.003240336896851659\n",
      "continue training\n",
      "Epoch 33, Batch 0, Loss: 0.0034304107539355755\n",
      "Epoch 33, Batch 1, Loss: 0.0027608282398432493\n",
      "Epoch 33, Average Train Loss: 0.0030956194968894124\n",
      "Epoch 33, Validation Loss: 0.0034100132761523128\n",
      "continue training\n",
      "Epoch 34, Batch 0, Loss: 0.0033641201443970203\n",
      "Epoch 34, Batch 1, Loss: 0.0027809888124465942\n",
      "Epoch 34, Average Train Loss: 0.0030725544784218073\n",
      "Epoch 34, Validation Loss: 0.0033165020868182182\n",
      "continue training\n",
      "Epoch 35, Batch 0, Loss: 0.003374730236828327\n",
      "Epoch 35, Batch 1, Loss: 0.0025130417197942734\n",
      "Epoch 35, Average Train Loss: 0.0029438859783113003\n",
      "Epoch 35, Validation Loss: 0.0028897172305732965\n",
      "continue training\n",
      "Epoch 36, Batch 0, Loss: 0.0034144201781600714\n",
      "Epoch 36, Batch 1, Loss: 0.0021441217977553606\n",
      "Epoch 36, Average Train Loss: 0.002779270987957716\n",
      "Epoch 36, Validation Loss: 0.0031930109253153205\n",
      "continue training\n",
      "Epoch 37, Batch 0, Loss: 0.003152999095618725\n",
      "Epoch 37, Batch 1, Loss: 0.0029894320759922266\n",
      "Epoch 37, Average Train Loss: 0.0030712155858054757\n",
      "Epoch 37, Validation Loss: 0.0033977647544816136\n",
      "continue training\n",
      "Epoch 38, Batch 0, Loss: 0.00304859085008502\n",
      "Epoch 38, Batch 1, Loss: 0.0032257982529699802\n",
      "Epoch 38, Average Train Loss: 0.0031371945515275\n",
      "Epoch 38, Validation Loss: 0.003176332451403141\n",
      "continue training\n",
      "Epoch 39, Batch 0, Loss: 0.0029711483512073755\n",
      "Epoch 39, Batch 1, Loss: 0.003364657750353217\n",
      "Epoch 39, Average Train Loss: 0.0031679030507802963\n",
      "Epoch 39, Validation Loss: 0.0030784725677222013\n",
      "continue training\n",
      "Epoch 40, Batch 0, Loss: 0.002814697800204158\n",
      "Epoch 40, Batch 1, Loss: 0.0038280682638287544\n",
      "Epoch 40, Average Train Loss: 0.003321383032016456\n",
      "Epoch 40, Validation Loss: 0.0026129918405786157\n",
      "continue training\n",
      "Epoch 41, Batch 0, Loss: 0.002785532269626856\n",
      "Epoch 41, Batch 1, Loss: 0.0037929241079837084\n",
      "Epoch 41, Average Train Loss: 0.003289228188805282\n",
      "Epoch 41, Validation Loss: 0.002913925563916564\n",
      "continue training\n",
      "Epoch 42, Batch 0, Loss: 0.0031254980713129044\n",
      "Epoch 42, Batch 1, Loss: 0.0022950908169150352\n",
      "Epoch 42, Average Train Loss: 0.00271029444411397\n",
      "Epoch 42, Validation Loss: 0.002825993113219738\n",
      "continue training\n",
      "Epoch 43, Batch 0, Loss: 0.002921115607023239\n",
      "Epoch 43, Batch 1, Loss: 0.002964621176943183\n",
      "Epoch 43, Average Train Loss: 0.002942868391983211\n",
      "Epoch 43, Validation Loss: 0.00283803534694016\n",
      "continue training\n",
      "Epoch 44, Batch 0, Loss: 0.0029152906499803066\n",
      "Epoch 44, Batch 1, Loss: 0.0028480335604399443\n",
      "Epoch 44, Average Train Loss: 0.0028816621052101254\n",
      "Epoch 44, Validation Loss: 0.002893533557653427\n",
      "continue training\n",
      "Epoch 45, Batch 0, Loss: 0.0029728496447205544\n",
      "Epoch 45, Batch 1, Loss: 0.002470106817781925\n",
      "Epoch 45, Average Train Loss: 0.0027214782312512398\n",
      "Epoch 45, Validation Loss: 0.00295301154255867\n",
      "Early stopping triggered\n",
      "Signal 0, SNR: 4.057704448699951\n",
      "Signal 1, SNR: 2.368415355682373\n",
      "Signal 2, SNR: 8.767961502075195\n",
      "Signal 3, SNR: 4.566816806793213\n",
      "Signal 4, SNR: 6.392796039581299\n",
      "Signal 5, SNR: 7.008566379547119\n",
      "Signal 6, SNR: 6.192497253417969\n",
      "Signal 7, SNR: 3.3983194828033447\n",
      "Signal 8, SNR: 2.071460723876953\n",
      "Signal 9, SNR: 9.472423553466797\n",
      "Signal 10, SNR: 9.067413330078125\n",
      "Signal 11, SNR: 8.31981086730957\n",
      "Signal 12, SNR: 10.53512954711914\n",
      "Signal 13, SNR: 7.592778205871582\n",
      "Signal 14, SNR: 6.172220706939697\n",
      "Signal 15, SNR: 3.8183400630950928\n",
      "Average SNR: 6.237665891647339\n",
      "Reconstructed signal saved as AE3_reconstructed.wav\n"
     ]
    }
   ],
   "source": [
    "# Assuming a sampling rate of 16 kHz\n",
    "sampling_rate = 16000\n",
    "signal_length_seconds = 6  # 6 seconds\n",
    "signal_length_samples = sampling_rate * signal_length_seconds  # Convert to samples\n",
    "\n",
    "# Function to get audio file paths\n",
    "def get_audio_files(directory_path):\n",
    "    return [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.wav')]\n",
    "\n",
    "# Directory path for training data\n",
    "train_directory_path = r'C:\\Kursmaterial\\Dl der Sprachsignalverarbeitung\\Computerübung 2\\signals\\Train_40'\n",
    "train_audio_files = get_audio_files(train_directory_path)\n",
    "\n",
    "# Directory path for validation data\n",
    "validation_directory_path = r'C:\\Kursmaterial\\Dl der Sprachsignalverarbeitung\\Computerübung 2\\signals\\Dev_16'\n",
    "validation_audio_files = get_audio_files(train_directory_path)\n",
    "\n",
    "\n",
    "# Directory path for test data\n",
    "test_directory_path = r'C:\\Kursmaterial\\Dl der Sprachsignalverarbeitung\\Computerübung 2\\signals\\Test_16'\n",
    "test_audio_files = get_audio_files(test_directory_path)\n",
    "\n",
    "\n",
    "\n",
    "# Training and testing data loaders\n",
    "frame_length = 512\n",
    "frame_length_test = 512\n",
    "\n",
    "# Update the Overlap\n",
    "overlap = int(0.5 * frame_length)   #select 50 % Overlap\n",
    "\n",
    "\n",
    "train_dataset = AudioDataset(train_audio_files, signal_length_samples, frame_length, overlap)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_dataset = AudioDataset(validation_audio_files, signal_length_samples, frame_length, overlap)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = AudioDataset(test_audio_files, signal_length_samples, frame_length_test, overlap)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to train and test a model\n",
    "def train_and_test_model(model_class, train_loader, validation_loader, test_loader, device, model_name, patience):\n",
    "    model = model_class().to(device)\n",
    "    train(model, train_loader, validation_loader, 2000, device, patience)  \n",
    "    test(model, test_loader, device)\n",
    "    test_and_save(model, test_loader, device, 0, model_name,  sampling_rate)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "patience = 5  # Number of epochs before stopping\n",
    "\n",
    "# Train and test AE3\n",
    "print(\"Training and Testing AE3\")\n",
    "train_and_test_model(AE3, train_loader, validation_loader, test_loader, device, \"AE3\", patience)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 45, Batch 0, Loss: 0.0029728496447205544\n",
    "Epoch 45, Batch 1, Loss: 0.002470106817781925\n",
    "Epoch 45, Average Train Loss: 0.0027214782312512398\n",
    "Epoch 45, Validation Loss: 0.00295301154255867\n",
    "Early stopping triggered"
   ]
  },
  
  
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
