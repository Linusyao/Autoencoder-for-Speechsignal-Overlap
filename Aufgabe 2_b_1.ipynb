{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare all three trained autoencoders using the test function and the 16\n",
    "test signals. For the overlap-add reconstruction choose an overlap of O = 0\n",
    "and the rectangular window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "# Autoencoder Models\n",
    "class AE1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE1, self).__init__()\n",
    "        self.encoder = nn.Linear(512, 16)\n",
    "        self.decoder = nn.Linear(16, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.encoder(x))\n",
    "        x = F.tanh(self.decoder(x))\n",
    "        return x\n",
    "class AE2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE2, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Linear(512, 128)\n",
    "        self.enc2 = nn.Linear(128, 64)\n",
    "        self.enc3 = nn.Linear(64, 16)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec1 = nn.Linear(16, 64)\n",
    "        self.dec2 = nn.Linear(64, 128)\n",
    "        self.dec3 = nn.Linear(128, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.enc1(x))\n",
    "        x = F.tanh(self.enc2(x))\n",
    "        x = F.tanh(self.enc3(x))\n",
    "        x = F.tanh(self.dec1(x))\n",
    "        x = F.tanh(self.dec2(x))\n",
    "        x = F.tanh(self.dec3(x))\n",
    "        return x\n",
    "\n",
    "class AE3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE3, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Linear(512, 384)\n",
    "        self.enc2 = nn.Linear(384, 256)\n",
    "        self.enc3 = nn.Linear(256, 128)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec1 = nn.Linear(128, 256)\n",
    "        self.dec2 = nn.Linear(256, 384)\n",
    "        self.dec3 = nn.Linear(384, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.enc1(x))\n",
    "        x = F.tanh(self.enc2(x))\n",
    "        x = F.tanh(self.enc3(x))\n",
    "        x = F.tanh(self.dec1(x))\n",
    "        x = F.tanh(self.dec2(x))\n",
    "        x = F.tanh(self.dec3(x))\n",
    "        return x\n",
    "\n",
    "# Custom Audio Dataset\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audio_files, signal_length, frame_length, overlap):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_files (list): List of paths to audio files.\n",
    "            signal_length (int): Desired length of the signal in samples (La).\n",
    "            frame_length (int): Frame length in samples (LF).\n",
    "            overlap (int): Overlap of frames in samples (O).\n",
    "        \"\"\"\n",
    "        self.audio_files = audio_files\n",
    "        self.signal_length = signal_length\n",
    "        self.frame_length = frame_length\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "    \n",
    "    def _adjust_frame_length_for_testing(self, frame):\n",
    "        if frame.shape[1] < 512:\n",
    "            padding = 512 - frame.shape[1]\n",
    "            frame = F.pad(frame, (0, padding))\n",
    "        elif frame.shape[1] > 512:\n",
    "            frame = frame[:, :512]\n",
    "        return frame\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_files[idx]\n",
    "        waveform, _ = torchaudio.load(audio_path)\n",
    "\n",
    "        # Truncate or Zero-pad the signal\n",
    "        waveform = self._adjust_length(waveform)\n",
    "\n",
    "        # Normalize the signal\n",
    "        waveform = self._normalize(waveform)\n",
    "\n",
    "        # Segment into frames\n",
    "        frames = self._segment_into_frames(waveform)\n",
    "\n",
    "        # Adjust frame length for testing\n",
    "        adjusted_frames = torch.zeros((frames.shape[0], 512))\n",
    "        for i, frame in enumerate(frames):\n",
    "            adjusted_frames[i] = self._adjust_frame_length_for_testing(frame.unsqueeze(0))\n",
    "\n",
    "        return adjusted_frames\n",
    "        \n",
    "\n",
    "    def _adjust_length(self, waveform):\n",
    "        if waveform.shape[1] > self.signal_length:\n",
    "            return waveform[:, :self.signal_length]\n",
    "        elif waveform.shape[1] < self.signal_length:\n",
    "            padding = self.signal_length - waveform.shape[1]\n",
    "            return F.pad(waveform, (0, padding))\n",
    "        else:\n",
    "            return waveform\n",
    "\n",
    "    def _normalize(self, waveform):\n",
    "        max_val = torch.max(torch.abs(waveform))\n",
    "        if max_val > 0:\n",
    "            return waveform / max_val\n",
    "        return waveform\n",
    "\n",
    "    def _segment_into_frames(self, waveform):\n",
    "        step = self.frame_length - self.overlap\n",
    "        num_frames = 1 + (waveform.shape[1] - self.frame_length) // step\n",
    "        frames = torch.zeros((num_frames, self.frame_length))\n",
    "\n",
    "        for i in range(num_frames):\n",
    "            start = i * step\n",
    "            end = start + self.frame_length\n",
    "            frames[i] = waveform[0, start:end]\n",
    "\n",
    "        return frames\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, epochs, device):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}\")\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch}, Average Loss: {avg_loss}\")\n",
    "\n",
    "# Testing Function\n",
    "def test(model, test_loader, device, overlap=0):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    total_snr = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            #print(data.shape)\n",
    "            reconstructed = model(data)\n",
    "            original_signal = overlap_add(data, overlap)\n",
    "            reconstructed_signal = overlap_add(reconstructed, overlap)\n",
    "            snr = calculate_snr(original_signal, reconstructed_signal)\n",
    "            print(f\"Signal {count}, SNR: {snr}\")\n",
    "            total_snr += snr\n",
    "            count += 1\n",
    "\n",
    "    avg_snr = total_snr / count\n",
    "    print(f\"Average SNR: {avg_snr}\")\n",
    "\n",
    "# Helper Functions\n",
    "def calculate_snr(original, reconstructed):\n",
    "    noise = original - reconstructed\n",
    "    signal_power = torch.mean(original ** 2)\n",
    "    noise_power = torch.mean(noise ** 2)\n",
    "    snr = 10 * torch.log10(signal_power / noise_power)\n",
    "    return snr.item()\n",
    "\n",
    "\n",
    "\n",
    "def overlap_add(frames, overlap):\n",
    "    frames = frames.squeeze()\n",
    "    frame_length = frames.shape[1] #L\n",
    "    frame_zahl= frames.shape[0] #N\n",
    "    step = frame_length - overlap\n",
    "    signal_length = step * (frames.shape[0] - 1) + frame_length\n",
    "    signal = torch.zeros(signal_length)\n",
    "    window = torch.ones(frame_length)  # Rectangular window\n",
    "\n",
    "    #for i, frame in enumerate(frames):\n",
    "        #start = i * step\n",
    "        #end = start + frame_length\n",
    "        #print(end-start, frame.size(), window.size())\n",
    "        #signal[start:end] += frame * window\n",
    "\n",
    "    for i in range(frame_zahl):\n",
    "        start = i *step\n",
    "        end = start + frame_length\n",
    "        #print(end-start, frames[i].size(), window.size())\n",
    "        signal[start:end] += frames[i] * window\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing AE1\n",
      "Epoch 0, Batch 0, Loss: 0.034443583339452744\n",
      "Epoch 0, Batch 1, Loss: 0.035759516060352325\n",
      "Epoch 0, Average Loss: 0.035101549699902534\n",
      "Epoch 1, Batch 0, Loss: 0.03293348848819733\n",
      "Epoch 1, Batch 1, Loss: 0.03614429384469986\n",
      "Epoch 1, Average Loss: 0.03453889116644859\n",
      "Epoch 2, Batch 0, Loss: 0.03237292170524597\n",
      "Epoch 2, Batch 1, Loss: 0.033498864620923996\n",
      "Epoch 2, Average Loss: 0.032935893163084984\n",
      "Epoch 3, Batch 0, Loss: 0.03166932240128517\n",
      "Epoch 3, Batch 1, Loss: 0.03195016086101532\n",
      "Epoch 3, Average Loss: 0.031809741631150246\n",
      "Epoch 4, Batch 0, Loss: 0.03146094083786011\n",
      "Epoch 4, Batch 1, Loss: 0.028840895742177963\n",
      "Epoch 4, Average Loss: 0.030150918290019035\n",
      "Epoch 5, Batch 0, Loss: 0.030722102150321007\n",
      "Epoch 5, Batch 1, Loss: 0.02812500298023224\n",
      "Epoch 5, Average Loss: 0.029423552565276623\n",
      "Epoch 6, Batch 0, Loss: 0.029600055888295174\n",
      "Epoch 6, Batch 1, Loss: 0.02911088801920414\n",
      "Epoch 6, Average Loss: 0.029355471953749657\n",
      "Epoch 7, Batch 0, Loss: 0.028682496398687363\n",
      "Epoch 7, Batch 1, Loss: 0.02939646691083908\n",
      "Epoch 7, Average Loss: 0.029039481654763222\n",
      "Epoch 8, Batch 0, Loss: 0.027588890865445137\n",
      "Epoch 8, Batch 1, Loss: 0.030439253896474838\n",
      "Epoch 8, Average Loss: 0.029014072380959988\n",
      "Epoch 9, Batch 0, Loss: 0.027781521901488304\n",
      "Epoch 9, Batch 1, Loss: 0.026370782405138016\n",
      "Epoch 9, Average Loss: 0.02707615215331316\n",
      "Epoch 10, Batch 0, Loss: 0.026804855093359947\n",
      "Epoch 10, Batch 1, Loss: 0.026992181316018105\n",
      "Epoch 10, Average Loss: 0.026898518204689026\n",
      "Epoch 11, Batch 0, Loss: 0.02633739449083805\n",
      "Epoch 11, Batch 1, Loss: 0.025572292506694794\n",
      "Epoch 11, Average Loss: 0.025954843498766422\n",
      "Epoch 12, Batch 0, Loss: 0.025176038965582848\n",
      "Epoch 12, Batch 1, Loss: 0.026919757947325706\n",
      "Epoch 12, Average Loss: 0.026047898456454277\n",
      "Epoch 13, Batch 0, Loss: 0.025283053517341614\n",
      "Epoch 13, Batch 1, Loss: 0.0231929924339056\n",
      "Epoch 13, Average Loss: 0.024238022975623608\n",
      "Epoch 14, Batch 0, Loss: 0.024034105241298676\n",
      "Epoch 14, Batch 1, Loss: 0.024891192093491554\n",
      "Epoch 14, Average Loss: 0.024462648667395115\n",
      "Epoch 15, Batch 0, Loss: 0.023587187752127647\n",
      "Epoch 15, Batch 1, Loss: 0.023396959528326988\n",
      "Epoch 15, Average Loss: 0.023492073640227318\n",
      "Epoch 16, Batch 0, Loss: 0.022908035665750504\n",
      "Epoch 16, Batch 1, Loss: 0.02284456416964531\n",
      "Epoch 16, Average Loss: 0.022876299917697906\n",
      "Epoch 17, Batch 0, Loss: 0.022074175998568535\n",
      "Epoch 17, Batch 1, Loss: 0.022941045463085175\n",
      "Epoch 17, Average Loss: 0.022507610730826855\n",
      "Epoch 18, Batch 0, Loss: 0.021224113181233406\n",
      "Epoch 18, Batch 1, Loss: 0.02313752844929695\n",
      "Epoch 18, Average Loss: 0.02218082081526518\n",
      "Epoch 19, Batch 0, Loss: 0.020755035802721977\n",
      "Epoch 19, Batch 1, Loss: 0.021861903369426727\n",
      "Epoch 19, Average Loss: 0.021308469586074352\n",
      "Signal 0, SNR: -2.4306938648223877\n",
      "Signal 1, SNR: -2.3864197731018066\n",
      "Signal 2, SNR: -1.4905266761779785\n",
      "Signal 3, SNR: -2.022045612335205\n",
      "Signal 4, SNR: -4.34893274307251\n",
      "Signal 5, SNR: -2.217319965362549\n",
      "Signal 6, SNR: -2.3439481258392334\n",
      "Signal 7, SNR: -4.468294143676758\n",
      "Signal 8, SNR: -2.6287941932678223\n",
      "Signal 9, SNR: -2.1979496479034424\n",
      "Signal 10, SNR: -2.017838716506958\n",
      "Signal 11, SNR: -2.2996158599853516\n",
      "Signal 12, SNR: -1.786344051361084\n",
      "Signal 13, SNR: -2.1135244369506836\n",
      "Signal 14, SNR: -2.6376917362213135\n",
      "Signal 15, SNR: -6.599023342132568\n",
      "Average SNR: -2.749310180544853\n",
      "Training and Testing AE2\n",
      "Epoch 0, Batch 0, Loss: 0.01936906762421131\n",
      "Epoch 0, Batch 1, Loss: 0.015488095581531525\n",
      "Epoch 0, Average Loss: 0.017428581602871418\n",
      "Epoch 1, Batch 0, Loss: 0.015649443492293358\n",
      "Epoch 1, Batch 1, Loss: 0.013818969950079918\n",
      "Epoch 1, Average Loss: 0.014734206721186638\n",
      "Epoch 2, Batch 0, Loss: 0.013833961449563503\n",
      "Epoch 2, Batch 1, Loss: 0.01308668963611126\n",
      "Epoch 2, Average Loss: 0.013460325542837381\n",
      "Epoch 3, Batch 0, Loss: 0.01238618791103363\n",
      "Epoch 3, Batch 1, Loss: 0.01497600506991148\n",
      "Epoch 3, Average Loss: 0.013681096490472555\n",
      "Epoch 4, Batch 0, Loss: 0.012561777606606483\n",
      "Epoch 4, Batch 1, Loss: 0.012321441434323788\n",
      "Epoch 4, Average Loss: 0.012441609520465136\n",
      "Epoch 5, Batch 0, Loss: 0.012629382312297821\n",
      "Epoch 5, Batch 1, Loss: 0.010906817391514778\n",
      "Epoch 5, Average Loss: 0.0117680998519063\n",
      "Epoch 6, Batch 0, Loss: 0.012510167434811592\n",
      "Epoch 6, Batch 1, Loss: 0.010570456273853779\n",
      "Epoch 6, Average Loss: 0.011540311854332685\n",
      "Epoch 7, Batch 0, Loss: 0.011780444532632828\n",
      "Epoch 7, Batch 1, Loss: 0.012842085212469101\n",
      "Epoch 7, Average Loss: 0.012311264872550964\n",
      "Epoch 8, Batch 0, Loss: 0.01186780072748661\n",
      "Epoch 8, Batch 1, Loss: 0.011961436830461025\n",
      "Epoch 8, Average Loss: 0.011914618778973818\n",
      "Epoch 9, Batch 0, Loss: 0.011698487214744091\n",
      "Epoch 9, Batch 1, Loss: 0.012082171626389027\n",
      "Epoch 9, Average Loss: 0.011890329420566559\n",
      "Epoch 10, Batch 0, Loss: 0.011109617538750172\n",
      "Epoch 10, Batch 1, Loss: 0.013824821449816227\n",
      "Epoch 10, Average Loss: 0.0124672194942832\n",
      "Epoch 11, Batch 0, Loss: 0.010999053716659546\n",
      "Epoch 11, Batch 1, Loss: 0.013611715286970139\n",
      "Epoch 11, Average Loss: 0.012305384501814842\n",
      "Epoch 12, Batch 0, Loss: 0.011350390501320362\n",
      "Epoch 12, Batch 1, Loss: 0.011510890908539295\n",
      "Epoch 12, Average Loss: 0.011430640704929829\n",
      "Epoch 13, Batch 0, Loss: 0.011366210877895355\n",
      "Epoch 13, Batch 1, Loss: 0.010700230486690998\n",
      "Epoch 13, Average Loss: 0.011033220682293177\n",
      "Epoch 14, Batch 0, Loss: 0.011300100944936275\n",
      "Epoch 14, Batch 1, Loss: 0.010218797251582146\n",
      "Epoch 14, Average Loss: 0.01075944909825921\n",
      "Epoch 15, Batch 0, Loss: 0.010973170399665833\n",
      "Epoch 15, Batch 1, Loss: 0.010785207152366638\n",
      "Epoch 15, Average Loss: 0.010879188776016235\n",
      "Epoch 16, Batch 0, Loss: 0.01035297755151987\n",
      "Epoch 16, Batch 1, Loss: 0.01252079103142023\n",
      "Epoch 16, Average Loss: 0.01143688429147005\n",
      "Epoch 17, Batch 0, Loss: 0.010668907314538956\n",
      "Epoch 17, Batch 1, Loss: 0.010526481084525585\n",
      "Epoch 17, Average Loss: 0.01059769419953227\n",
      "Epoch 18, Batch 0, Loss: 0.010542982257902622\n",
      "Epoch 18, Batch 1, Loss: 0.010312946513295174\n",
      "Epoch 18, Average Loss: 0.010427964385598898\n",
      "Epoch 19, Batch 0, Loss: 0.010463323444128036\n",
      "Epoch 19, Batch 1, Loss: 0.009916790761053562\n",
      "Epoch 19, Average Loss: 0.0101900571025908\n",
      "Signal 0, SNR: 0.6926167607307434\n",
      "Signal 1, SNR: 0.3949950933456421\n",
      "Signal 2, SNR: 0.872685432434082\n",
      "Signal 3, SNR: 0.49886661767959595\n",
      "Signal 4, SNR: 0.3816598355770111\n",
      "Signal 5, SNR: 1.1981172561645508\n",
      "Signal 6, SNR: 1.1916078329086304\n",
      "Signal 7, SNR: 0.4253290891647339\n",
      "Signal 8, SNR: 0.366115003824234\n",
      "Signal 9, SNR: 0.8314921855926514\n",
      "Signal 10, SNR: 0.9574590921401978\n",
      "Signal 11, SNR: 1.0337926149368286\n",
      "Signal 12, SNR: 0.811104416847229\n",
      "Signal 13, SNR: 0.7780016660690308\n",
      "Signal 14, SNR: 0.6250056624412537\n",
      "Signal 15, SNR: 0.366224467754364\n",
      "Average SNR: 0.7140670642256737\n",
      "Training and Testing AE3\n",
      "Epoch 0, Batch 0, Loss: 0.014046578668057919\n",
      "Epoch 0, Batch 1, Loss: 0.012430543079972267\n",
      "Epoch 0, Average Loss: 0.013238560874015093\n",
      "Epoch 1, Batch 0, Loss: 0.012294873595237732\n",
      "Epoch 1, Batch 1, Loss: 0.012048142030835152\n",
      "Epoch 1, Average Loss: 0.012171507813036442\n",
      "Epoch 2, Batch 0, Loss: 0.01251592393964529\n",
      "Epoch 2, Batch 1, Loss: 0.00926295854151249\n",
      "Epoch 2, Average Loss: 0.01088944124057889\n",
      "Epoch 3, Batch 0, Loss: 0.011549572460353374\n",
      "Epoch 3, Batch 1, Loss: 0.010635356418788433\n",
      "Epoch 3, Average Loss: 0.011092464439570904\n",
      "Epoch 4, Batch 0, Loss: 0.010450251400470734\n",
      "Epoch 4, Batch 1, Loss: 0.011768262833356857\n",
      "Epoch 4, Average Loss: 0.011109257116913795\n",
      "Epoch 5, Batch 0, Loss: 0.010595740750432014\n",
      "Epoch 5, Batch 1, Loss: 0.007994444109499454\n",
      "Epoch 5, Average Loss: 0.009295092429965734\n",
      "Epoch 6, Batch 0, Loss: 0.009606617502868176\n",
      "Epoch 6, Batch 1, Loss: 0.008482425473630428\n",
      "Epoch 6, Average Loss: 0.009044521488249302\n",
      "Epoch 7, Batch 0, Loss: 0.00895124301314354\n",
      "Epoch 7, Batch 1, Loss: 0.007816188968718052\n",
      "Epoch 7, Average Loss: 0.008383715990930796\n",
      "Epoch 8, Batch 0, Loss: 0.008013865910470486\n",
      "Epoch 8, Batch 1, Loss: 0.0086524011567235\n",
      "Epoch 8, Average Loss: 0.008333133533596992\n",
      "Epoch 9, Batch 0, Loss: 0.007932639680802822\n",
      "Epoch 9, Batch 1, Loss: 0.006196369417011738\n",
      "Epoch 9, Average Loss: 0.00706450454890728\n",
      "Epoch 10, Batch 0, Loss: 0.007436147890985012\n",
      "Epoch 10, Batch 1, Loss: 0.0057168882340192795\n",
      "Epoch 10, Average Loss: 0.006576518062502146\n",
      "Epoch 11, Batch 0, Loss: 0.006558799650520086\n",
      "Epoch 11, Batch 1, Loss: 0.007073278538882732\n",
      "Epoch 11, Average Loss: 0.006816039094701409\n",
      "Epoch 12, Batch 0, Loss: 0.00630014855414629\n",
      "Epoch 12, Batch 1, Loss: 0.006171468645334244\n",
      "Epoch 12, Average Loss: 0.006235808599740267\n",
      "Epoch 13, Batch 0, Loss: 0.005452530458569527\n",
      "Epoch 13, Batch 1, Loss: 0.0076748766005039215\n",
      "Epoch 13, Average Loss: 0.006563703529536724\n",
      "Epoch 14, Batch 0, Loss: 0.005645155441015959\n",
      "Epoch 14, Batch 1, Loss: 0.005312927067279816\n",
      "Epoch 14, Average Loss: 0.005479041254147887\n",
      "Epoch 15, Batch 0, Loss: 0.005263903643935919\n",
      "Epoch 15, Batch 1, Loss: 0.005387827754020691\n",
      "Epoch 15, Average Loss: 0.005325865698978305\n",
      "Epoch 16, Batch 0, Loss: 0.004879127722233534\n",
      "Epoch 16, Batch 1, Loss: 0.005647492129355669\n",
      "Epoch 16, Average Loss: 0.0052633099257946014\n",
      "Epoch 17, Batch 0, Loss: 0.004881920292973518\n",
      "Epoch 17, Batch 1, Loss: 0.004494825843721628\n",
      "Epoch 17, Average Loss: 0.004688373068347573\n",
      "Epoch 18, Batch 0, Loss: 0.0046270424500107765\n",
      "Epoch 18, Batch 1, Loss: 0.004504743963479996\n",
      "Epoch 18, Average Loss: 0.004565893206745386\n",
      "Epoch 19, Batch 0, Loss: 0.004609288182109594\n",
      "Epoch 19, Batch 1, Loss: 0.0037852665409445763\n",
      "Epoch 19, Average Loss: 0.004197277361527085\n",
      "Signal 0, SNR: 2.9344067573547363\n",
      "Signal 1, SNR: 1.5107181072235107\n",
      "Signal 2, SNR: 4.847681045532227\n",
      "Signal 3, SNR: 2.927239179611206\n",
      "Signal 4, SNR: 3.4193029403686523\n",
      "Signal 5, SNR: 5.492913246154785\n",
      "Signal 6, SNR: 3.7744271755218506\n",
      "Signal 7, SNR: 2.3917226791381836\n",
      "Signal 8, SNR: 1.6530966758728027\n",
      "Signal 9, SNR: 6.799444198608398\n",
      "Signal 10, SNR: 5.96925687789917\n",
      "Signal 11, SNR: 6.190363883972168\n",
      "Signal 12, SNR: 6.7950968742370605\n",
      "Signal 13, SNR: 4.746736526489258\n",
      "Signal 14, SNR: 4.5690083503723145\n",
      "Signal 15, SNR: 2.610827922821045\n",
      "Average SNR: 4.1645151525735855\n"
     ]
    }
   ],
   "source": [
    "# Assuming a sampling rate of 16 kHz\n",
    "sampling_rate = 16000\n",
    "signal_length_seconds = 6  # 6 seconds\n",
    "signal_length_samples = sampling_rate * signal_length_seconds  # Convert to samples\n",
    "\n",
    "# Function to get audio file paths\n",
    "def get_audio_files(directory_path):\n",
    "    return [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.wav')]\n",
    "\n",
    "# Directory path for training data\n",
    "train_directory_path = r'C:\\Kursmaterial\\Dl der Sprachsignalverarbeitung\\Computerübung 2\\signals\\Train_40'\n",
    "train_audio_files = get_audio_files(train_directory_path)\n",
    "\n",
    "# Directory path for test data\n",
    "test_directory_path = r'C:\\Kursmaterial\\Dl der Sprachsignalverarbeitung\\Computerübung 2\\signals\\Test_16'\n",
    "test_audio_files = get_audio_files(test_directory_path)\n",
    "\n",
    "# Training and testing data loaders\n",
    "frame_length = 512\n",
    "frame_length_test = 512\n",
    "train_dataset = AudioDataset(train_audio_files, signal_length_samples, frame_length, overlap=0)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = AudioDataset(test_audio_files, signal_length_samples, frame_length_test, overlap=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to train and test a model\n",
    "def train_and_test_model(model_class, train_loader, test_loader, device):\n",
    "    model = model_class().to(device)\n",
    "    train(model, train_loader, 20, device)  # Corrected the order of arguments\n",
    "    test(model, test_loader, device)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Train and test AE1\n",
    "print(\"Training and Testing AE1\")\n",
    "train_and_test_model(AE1, train_loader, test_loader, device)\n",
    "\n",
    "# Train and test AE2\n",
    "print(\"Training and Testing AE2\")\n",
    "train_and_test_model(AE2, train_loader, test_loader, device)\n",
    "\n",
    "# Train and test AE3\n",
    "print(\"Training and Testing AE3\")\n",
    "train_and_test_model(AE3, train_loader, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
